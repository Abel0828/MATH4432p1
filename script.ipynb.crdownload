{"cells":[{"metadata":{"_cell_guid":"ec5cb74d-f516-4e05-adf1-400fd36d3276","_uuid":"08ec3066c80cb782bd53407733dbe11149f23fd6"},"cell_type":"markdown","source":"# Implementation of Deep Learninig Model"},{"metadata":{"_cell_guid":"0b839f1d-5ad3-48cc-b1c7-4849b7f38bdc","_uuid":"86b330c69cb560c5c33b4b41302c73d026f9371e"},"cell_type":"markdown","source":"#  Load Data"},{"metadata":{"_cell_guid":"a470234f-8daa-45a9-9d5a-d38a00ddbef4","_uuid":"90d50d7d42c2a17986077833fa2b7c4563992eb7","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\nimport matplotlib.pyplot as plt\nimport os\nimport csv","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"ba1ed885-d0d7-4399-822f-878e03c5f80b","_uuid":"68768faea64baf248b09a0391a7f80883e7ecbc6","collapsed":true,"trusted":true},"cell_type":"code","source":"def readData(datafile,flatten=True, discrete=False):\n    # Param: datafile -- the filename of the data to read\n    # Param: flatten-- decidee whether to return the value as a one dimentional vector\n    # Param: discrete -- decide whether to return a grayscale integer value from 0-255\n\n    data=[]\n    labels=[]\n    with open(datafile, 'r') as csv_file:\n        for row in csv.reader(csv_file, delimiter=' '):\n            # The first column is the label\n            label = str(int(float(row[0])))\n\n            # The rest of columns are pixels\n            pixels = [float(pixel) for pixel in row[1:] if pixel and (not pixel.isspace())]\n            # This array will be of 1D with length 256\n            # The pixel intensity values are integers from 0 to 255\n            if discrete:\n                pixels = [round((float(pixel) + 1) / 2 * 255) for pixel in pixels]\n            pixels = np.array(pixels)\n            # Reshape the array into 28 x 28 array (2-dimensional array)\n            # could remove this line if want the pixels to be flattened\n            if not flatten:\n                pixels = pixels.reshape((16, 16))\n            data.append(pixels)\n            labels.append(label)\n\n    return data,labels\n","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"313739b3-8b7b-4ef3-a392-07aa11b76821","_uuid":"4f69f8f1e2e1a668f39af25eccbf033e47eb88ec","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train, Y_train = readData('../input/zip.train')\nX_test, Y_test = readData('../input/zip.test')","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"e3d6f68d-5cc5-4910-9fa6-5d046d6c28d2","_uuid":"a45f92be872bf6aadc56dc7a0b4a3b9c55987e08","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\nY_train = np.array(Y_train)\n\nX_test = np.array(X_test)\nY_test = np.array(Y_test)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"982b183e-aed5-4d35-abda-fd66e609b110","_uuid":"e987048f4178b6dd2054b8c381088366ec7c1428","scrolled":false,"trusted":true},"cell_type":"code","source":"print('Shape of train df: {}'.format(X_train.shape))\nprint('Shape of test df: {}'.format(X_test.shape))\nprint('Shape of train labels: {}'.format(Y_train.shape))\n\nX_train = X_train.astype('float32').reshape(X_train.shape[0], 16, 16, 1)\nX_test = X_test.astype('float32').reshape(X_test.shape[0], 16, 16, 1)\ninput_shape = (16, 16, 1)","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"e2eb6471-70ab-4883-90a6-844ff09f2e74","_uuid":"86c7cc395587776862c09faa2349b84f5f4a609d"},"cell_type":"markdown","source":"## Change label to one hot encoding"},{"metadata":{"_cell_guid":"fe1cd11d-ffb9-425c-9234-d52ac34dccdd","_uuid":"d1f87cf895fd363141da77bf4ca847fef8aff2f8","scrolled":false,"trusted":true},"cell_type":"code","source":"num_classes = 10\nY_train = keras.utils.to_categorical(Y_train, num_classes)\nY_test = keras.utils.to_categorical(Y_test, num_classes)\nprint(Y_train.shape)","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"9fb80a1f-3d83-495e-bae9-3a479b7bc5fe","_uuid":"9ad8b5192599594ebc82b768df7f210f1c9d5018"},"cell_type":"markdown","source":"# Build CNN  "},{"metadata":{"_cell_guid":"1de21b95-8a99-4b43-92c7-a672f9bf1234","_uuid":"036f780970ca8d04509c44eaebd6c321588820ef","collapsed":true,"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"8cf7b946-43e2-4fe5-8f4c-02cb61bd5ca2","_uuid":"3a45f76935574c0267b965c86acaa724f5a3da16","collapsed":true,"trusted":true},"cell_type":"code","source":"def build_cnn(dropout_rate=0.25, optimizer=None, momentum=0.1, learning_rate=1e-3, \n                    activation = 'relu', weight_constraint = 5):\n    \n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation =activation, input_shape = (16, 16,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation =activation))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(dropout_rate))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation =activation))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation =activation))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n\n    \n    if(optimizer is None or optimizer == 'SGD'):\n        optimizer = SGD(lr=learning_rate, momentum=momentum)\n    elif(optimizer == 'RMSprop'):\n        optimizer = RMSprop(lr=learning_rate)\n    elif(optimizer == 'Adagrad'):\n        optimizer = Adagrad(lr=learning_rate)\n    elif(optimizer == 'Adadelta'):\n        optimizer = Adadelta(lr=learning_rate)\n    elif(optimizer == 'Adam'):\n        optimizer = Adam(lr=learning_rate)\n    elif(optimizer == 'Adamax'):\n        optimizer = Adamax(lr=learning_rate)\n    elif(optimizer == 'Nadam'):\n        optimizer = Nadam(lr=learning_rate)\n        \n        \n        \n    \n    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer,\n              metrics=['accuracy'])\n        \n    return model\n\n\n","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"a44563f4-15bb-4257-aaad-2959e20ceca9","_uuid":"5fe6210a66e22d920f1a676ae974147464c8a2e1"},"cell_type":"markdown","source":"### Train CNN Model"},{"metadata":{"_cell_guid":"2ec767fc-46c3-4cc5-b906-9f0fd86393f1","_uuid":"10c2727c81ee4112cf2b040a55485ffeeb15b670","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nimport pickle\n\n'''\nTrain CNN model using input data, build function of model architecture, best parameter \nfrom previous search and other optional training parameters.\nIf the validation data are given, then the model is trained on part of the training \ndataset and evaluate on the remaining, while the training history will be saved as\npickle files.\nIf the validation data are None, then the model is trained on the whole dataset.\n'''\n\ndef train_cnn(X, Y, best_params, max_epoch, build_fn, class_weight=None, X_val=None, Y_val=None):\n    #Generate more data for training\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images \n     \n    #reduce learning rate when the metric does not improve after epochs\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, \n                                                verbose=1, factor=0.5, min_lr=0.00001)\n\n    datagen.fit(X_train)\n\n    batch_size = int(best_params['batch_size'])\n    del best_params['batch_size']\n    \n    model = build_fn(**best_params)\n    #optimizer = RMSprop()\n    #model = build_cnn_model(optimizer = optimizer)\n\n\n    \n        \n#Save and load model config using json every 2 epochs\n\n    for i in range(0, max_epoch//5):\n        print(\"Epoch {} - {}\".format(5*i, 5*i+4))\n        if(i > 0):\n            model = load_model(outfile)\n            #model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer,\n              #metrics=['accuracy'])\n    \n        h = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = 5, steps_per_epoch=X_train.shape[0] // batch_size,\n                              validation_data = (X_val,Y_val)if X_val is not None else None ,\n                              verbose = 2, class_weight = class_weight,\n                              callbacks = [learning_rate_reduction])\n    \n        outfile = 'Epoch {} - {}.h5'.format(5*i, 5*i+4)\n    \n        model.save(outfile)\n        #save training history\n        if(X_val is not None):\n            with open('Epoch {} - {}_history.pickle'.format(5*i, 5*i+4), 'wb') as hist_file:\n                pickle.dump(h.history, hist_file)\n    return model","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"2b1f01d7-6eec-408f-948e-8854ef25ea12","_uuid":"9bb43ae4dbbb119e89c545c546e87c9f8896d99f","trusted":true},"cell_type":"code","source":"best_params = {'optimizer': RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), 'batch_size': 86}\n\nmodel = train_cnn(X = X_train, Y=Y_train, best_params=best_params, max_epoch=25, \n          build_fn=build_cnn, X_val=X_test, Y_val=Y_test)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"aba9e851-0819-49e0-bfbf-afb18cf7e395","_uuid":"34047468540c434e2ff5847ebcc2f022e26fd8cc"},"cell_type":"markdown","source":"## Validation"},{"metadata":{"_cell_guid":"c5ec9338-0e5f-4146-9527-819480fff129","_uuid":"cf4dffad5472cb43458fc00505d35633330f22c8","trusted":true},"cell_type":"code","source":"val_loss, val_acc = model.evaluate(X_test, Y_test, verbose=0)\n\nprint(' Validation loss: {:.6f}, Validation accuracy: {:.6f}'.format(val_loss, val_acc))","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"5c38a16c-162e-4819-ad51-0870580240b6","_uuid":"b2be1a1e218ddc10ebbfc14527662a7bb9a4b8b1"},"cell_type":"markdown","source":"## Analysis"},{"metadata":{"_cell_guid":"2281ebea-79e7-456e-af3b-eba11e1eb680","_uuid":"dc18c3acd2f274b78043b91ddca592aa21464e2c","scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = model.predict(X_test) # shape: (?, 10)\ny_pred_class = np.argmax(y_pred, axis=1) #shape: (?,)\ny_true = np.argmax(Y_test, axis=1) #shape: (?,)\ncm = confusion_matrix(y_true, y_pred_class)\nprint(cm)\n\n\n","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"b99af571-4c09-4510-9b2c-4c0d02ff633e","_uuid":"a395d6a3c75caddcc548598edd0ae8747162ef38","scrolled":false,"trusted":true},"cell_type":"code","source":"labels = []\nmis_pred = []\ncounts = []\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        if(i == j): \n            continue\n        elif(cm[i][j] > 0):\n            counts.append(cm[i][j])\n            labels.append(i)\n            mis_pred.append(j)\npred_df = pd.DataFrame({'labels': labels, 'pred': mis_pred, 'count': counts})\npred_df = pred_df[['labels', 'pred', 'count']]\nprint(pred_df.sort_values(by='count', ascending=False))\n            ","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"f9e59689-8a6a-466d-bd81-cf25bc2d6ebf","_uuid":"57c0868b821d68c3c965b2a94af4dd0b8f5ed968"},"cell_type":"markdown","source":"## Visualization of training history "},{"metadata":{"_cell_guid":"5e7405ba-95b4-4498-8a82-b3e177d0dd20","_uuid":"db4bb1d837ba164cffaf67cb7243f1914fcd6286"},"cell_type":"markdown","source":"### Restore training history "},{"metadata":{"_cell_guid":"04957e91-deef-4557-b8f9-c697ab6a89ab","_uuid":"a5733ffafcc6c7ada0a878fc34f2743c8bcba283","scrolled":true,"trusted":true},"cell_type":"code","source":"import os\nimport re\n#initialize an empty history dictionary\nhistory = {'acc':[], 'val_acc':[], 'loss': [], 'val_loss':[], 'lr':[]}\n\ni = 0\nwhile (i < 25):\n    for file in os.listdir('.'):\n        if(re.search(r'history', file)):\n            epoch_num = re.search(r'\\d+', file).group()\n            \n            print(file)\n            print('epoch#: {}'.format(epoch_num))\n            print('i: {}'.format(i))\n            if(int(epoch_num) == i):\n                with open(file, 'rb') as hist_file:\n                    temp_hist = pickle.load(hist_file)\n        \n                for item in history:\n                    \n                    history[item]+=temp_hist[item]\n                i+=5\n        ","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"1b7b9a28-895a-45d9-a7c7-5c1e40b37815","_uuid":"f8d26a95cf84dcd088725a805e373fec08e014dc"},"cell_type":"markdown","source":"### Plot the training history "},{"metadata":{"_cell_guid":"99c27aa1-12c7-48a1-b36e-509e84d4a8fe","_uuid":"697dd6dd0f654f049dd70ea6b9f3c9e0b468fee0","scrolled":true,"trusted":true},"cell_type":"code","source":"#  \"Accuracy\"\nplt.plot(history['acc'])\nplt.plot(history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\n# \"Loss\"\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n#\"Learning Rate\"\nplt.subplot(3,1,3)\nplt.plot(history['lr'])\nplt.title('Learning Rate')\nplt.show()","execution_count":34,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}